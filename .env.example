# ConfiguraciÃ³n del Sistema de AtenciÃ³n al Cliente

# ========================================
# OPCIÃ“N 1: GitHub Models (Recomendado) ðŸŒŸ
# ========================================
# Usa modelos gratuitos de GitHub con tu GitHub Personal Access Token
# Crear token en: https://github.com/settings/tokens
# Permisos requeridos: ninguno especial, solo token bÃ¡sico

# LLM_TOKEN=ghp_your_github_personal_access_token
# LLM_ENDPOINT=https://models.github.ai/inference
# LLM_MODEL=openai/gpt-4.1-mini

# Modelos disponibles en GitHub:
# - openai/gpt-4.1-mini (recomendado, rÃ¡pido y eficiente)
# - Ver mÃ¡s: https://github.com/marketplace/models

# ========================================
# OPCIÃ“N 2: OpenAI API
# ========================================
# USE_OPENAI=true
# OPENAI_API_KEY=sk-your_openai_api_key

# ========================================
# OPCIÃ“N 3: Ollama Local (Por Defecto)
# ========================================
# Modelo de Ollama (recomendados por velocidad para Codespaces)
# - qwen2.5:0.5b  -> Ultra-rÃ¡pido (~5-10s) âš¡ [RECOMENDADO]
# - tinyllama     -> Muy rÃ¡pido (~8-12s)
# - phi3:mini     -> RÃ¡pido (~10-15s), excelente calidad
# - llama3.2:1b   -> Balanceado (~20-25s)
OLLAMA_MODEL=qwen2.5:0.5b
