# Configuraci칩n del Sistema de Atenci칩n al Cliente

# ========================================
# OPCI칍N 1: GitHub Models (Recomendado) 游
# ========================================
# Usa modelos gratuitos de GitHub con tu GitHub Personal Access Token
# Crear token en: https://github.com/settings/tokens
# Permisos requeridos: ninguno especial, solo token b치sico

# LLM_TOKEN=ghp_your_github_personal_access_token
# LLM_ENDPOINT=https://models.github.ai/inference
# LLM_MODEL=openai/gpt-4.1-mini

# Modelos disponibles en GitHub:
# - openai/gpt-4.1-mini (recomendado, r치pido y eficiente)
# - Ver m치s: https://github.com/marketplace/models

# ========================================
# OPCI칍N 2: OpenAI API
# ========================================
# USE_OPENAI=true
# OPENAI_API_KEY=sk-your_openai_api_key

# ========================================
# OPCI칍N 3: Ollama Local (Por Defecto)
# ========================================
# Modelo de Ollama (recomendados por velocidad para Codespaces)
# - qwen2.5:0.5b  -> [RECOMENDADO Codespaces CPU]
# - tinyllama     -> (~8-12s)
# - phi3:mini     -> (~10-25s), mejor calidad
# - llama3.2:1b   -> (~20-45s) Balanceado 
OLLAMA_MODEL=qwen2.5:0.5b
