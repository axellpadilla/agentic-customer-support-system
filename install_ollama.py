#!/usr/bin/env python3
"""
Instalador autom√°tico de Ollama usando el m√©todo binario oficial
Basado en: https://github.com/BlackTechX011/Ollama-in-GitHub-Codespaces
"""
import subprocess
import sys
import time
import os

def run_command(cmd, description="", timeout=120, shell=True):
    """Ejecuta un comando y muestra el resultado."""
    print(f"üîß {description}")
    try:
        result = subprocess.run(
            cmd,
            shell=shell,
            capture_output=True,
            text=True,
            timeout=timeout
        )
        
        if result.returncode == 0:
            print(f"‚úÖ {description} - Exitoso")
            return True
        else:
            print(f"‚ùå {description} - Fall√≥")
            if result.stderr:
                print(f"   Error: {result.stderr[:200]}")
            return False
    except subprocess.TimeoutExpired:
        print(f"‚è∞ {description} - Tiempo agotado")
        return False
    except Exception as e:
        print(f"‚ùå {description} - Error: {e}")
        return False

def check_ollama_installed():
    """Verifica si Ollama ya est√° instalado."""
    try:
        result = subprocess.run(
            ["ollama", "--version"],
            capture_output=True,
            timeout=5
        )
        if result.returncode == 0:
            print("‚úÖ Ollama ya est√° instalado")
            return True
    except:
        pass
    return False

def install_ollama_binary():
    """Instala Ollama usando el script oficial (m√©todo comprobado)."""
    print("\nüì¶ Instalando Ollama con el instalador oficial...")
    
    # Descargar e instalar usando el script oficial
    if not run_command(
        "curl -fsSL https://ollama.com/install.sh | sh",
        "Descargando e instalando Ollama",
        timeout=300,  # 5 minutos
        shell=True
    ):
        return False
    
    # Verificar instalaci√≥n
    if not run_command(
        "ollama --version",
        "Verificando instalaci√≥n",
        timeout=10,
        shell=True
    ):
        return False
    
    print("‚úÖ Ollama instalado correctamente")
    return True

def start_ollama_server():
    """Inicia el servidor de Ollama en segundo plano."""
    print("\nüñ•Ô∏è  Iniciando servidor Ollama...")
    
    try:
        # Iniciar servidor en segundo plano
        process = subprocess.Popen(
            ["ollama", "serve"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True
        )
        
        # Esperar a que el servidor est√© listo
        print("‚è≥ Esperando a que el servidor est√© listo...")
        time.sleep(5)
        
        # Verificar que el servidor responde
        try:
            import requests
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            if response.status_code == 200:
                print("‚úÖ Servidor Ollama iniciado correctamente")
                return True
        except:
            pass
        
        print("‚ö†Ô∏è  El servidor puede no estar completamente listo")
        return True
        
    except Exception as e:
        print(f"‚ùå Error al iniciar servidor: {e}")
        return False

def pull_model(model_name):
    """Descarga el modelo especificado."""
    print(f"\nü§ñ Descargando modelo: {model_name}")
    print("‚è≥ Esto puede tomar varios minutos...")
    
    if not run_command(
        ["ollama", "pull", model_name],
        f"Descargando {model_name}",
        timeout=600  # 10 minutos
    ):
        return False
    
    print(f"‚úÖ Modelo {model_name} descargado correctamente")
    return True

def main():
    """Funci√≥n principal de instalaci√≥n."""
    print("ü§ñ Instalador Autom√°tico de Ollama para Codespaces")
    print("=" * 55)
    
    # Obtener nombre del modelo del entorno
    model_name = os.getenv('OLLAMA_MODEL', 'qwen2.5:0.5b')
    print(f"Modelo objetivo: {model_name} (ultra-r√°pido para Codespaces)\n")
    
    # Verificar si ya est√° instalado
    if check_ollama_installed():
        print("‚úÖ Ollama ya est√° disponible")
    else:
        # Instalar Ollama usando el m√©todo binario oficial
        if not install_ollama_binary():
            print("\n‚ùå La instalaci√≥n fall√≥")
            print("\nüìã Instalaci√≥n manual:")
            print("   curl -fsSL https://ollama.com/install.sh | sh")
            sys.exit(1)
    
    # Iniciar servidor
    if not start_ollama_server():
        print("\n‚ö†Ô∏è  El servidor puede necesitar iniciarse manualmente")
        print("   Ejecuta: ollama serve")
    
    # Descargar modelo
    if not pull_model(model_name):
        print(f"\n‚ö†Ô∏è  El modelo {model_name} puede descargarse manualmente")
        print(f"   Ejecuta: ollama pull {model_name}")
    
    print("\nüéâ ¬°Instalaci√≥n completa!")
    print("üöÄ Puedes ejecutar: streamlit run app.py")

if __name__ == "__main__":
    main()
